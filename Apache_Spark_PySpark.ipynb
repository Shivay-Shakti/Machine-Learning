{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivay-Shakti/Machine-Learning/blob/main/Apache_Spark_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation "
      ],
      "metadata": {
        "id": "gI2x0JF2Cj2V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3-Pa5tMtutr"
      },
      "outputs": [],
      "source": [
        "# data set downoad instructions from kaggle. We are using opensource temperature data available at Kaggle.\n",
        "#We will download data using kaggle API at run time. To understand how kaggle API works, please visit kaggle link \n",
        "# https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q kaggle"
      ],
      "metadata": {
        "id": "FBkbEMkDyGF8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "FgFjmVJKypsE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload Kaggle JSON API credential file"
      ],
      "metadata": {
        "id": "TjAMV1LOCtP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "H5OQ706zytPe",
        "outputId": "ce870159-5fad-4515-f86a-b4e381615197"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-50f607da-5e83-4483-a2b0-2cf044ff2b2c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-50f607da-5e83-4483-a2b0-2cf044ff2b2c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"shivayshaktidubey\",\"key\":\"a720124ba65dfecd557ee58c645b3922\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create directory to save Json credential file, copy JSON file and change permissions \n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "lpqyY5V3yyni"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download kaggle temperature dataset daily-temperature-of-major-cities\n",
        "! kaggle datasets download -d sudalairajkumar/daily-temperature-of-major-cities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scYJZT52zhRr",
        "outputId": "286c8baf-e1b7-46a5-8fad-8656f994b73c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading daily-temperature-of-major-cities.zip to /content\n",
            "\r  0% 0.00/12.9M [00:00<?, ?B/s]\r 70% 9.00M/12.9M [00:00<00:00, 74.7MB/s]\n",
            "\r100% 12.9M/12.9M [00:00<00:00, 96.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip downloaded file\n",
        "! unzip daily-temperature-of-major-cities.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaXs8jijzkd-",
        "outputId": "c3597270-ec19-40af-98aa-946da844c5d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  daily-temperature-of-major-cities.zip\n",
            "  inflating: city_temperature.csv    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "un-ucP48Do0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Enviornment- Install JDK 8, Pyspark version 3.2.1"
      ],
      "metadata": {
        "id": "zOzFJYJNDpmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Install java\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed pyspark==3.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqIYgdyI0TEZ",
        "outputId": "51a6b484-959b-4a79-8849-90477496477e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"1.8.0_352\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_352-8u352-ga-1~20.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.352-b08, mixed mode)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark==3.2.1\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853643 sha256=d1e3b5c261b684704fc867a559afe41007a34db5db844640f9a1c873a0dc77ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/94/83/915c9059e4b038e2d43a6058f307fe1c3e8536e5745f3b23b7\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pyspark --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabL29yV1PeE",
        "outputId": "400a1787-7a07-4a84-f617-ba2faede6cc7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.2.1\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.12.15, OpenJDK 64-Bit Server VM, 1.8.0_352\n",
            "Branch HEAD\n",
            "Compiled by user hgao on 2022-01-20T19:26:14Z\n",
            "Revision 4f25b3f71238a00508a356591553f2dfa89f8290\n",
            "Url https://github.com/apache/spark\n",
            "Type --help for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Pyspark and creating spark session"
      ],
      "metadata": {
        "id": "WP99SgAlEBOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set enviornment variable SPARK_VERSION\n",
        "! export SPARK_VERSION=3.2.1\n",
        "import pyspark\n",
        "import pyspark.sql\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.config('spark.ui.port', '4050').getOrCreate()"
      ],
      "metadata": {
        "id": "qWUgchiA2Ayd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing data into spark"
      ],
      "metadata": {
        "id": "f_C_yChFETHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import functions as F\n",
        "data_path = '/content/city_temperature.csv'\n",
        "data = spark.read.csv(data_path, header=True)"
      ],
      "metadata": {
        "id": "Vp1wrjPy0-jL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect Schema\n",
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa7e9OnDJleo",
        "outputId": "54658d39-467f-4c02-f1e7-e8b3dfe55a0d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Region: string (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- State: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Month: string (nullable = true)\n",
            " |-- Day: string (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            " |-- AvgTemperature: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y1XxYSS1mgo",
        "outputId": "5fce65fb-d919-4099-d842-24286aaf6c1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='1', Year='1995', AvgTemperature='64.2'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='2', Year='1995', AvgTemperature='49.4'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='3', Year='1995', AvgTemperature='48.8'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='4', Year='1995', AvgTemperature='46.4'),\n",
              " Row(Region='Africa', Country='Algeria', State=None, City='Algiers', Month='1', Day='5', Year='1995', AvgTemperature='47.9')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLfsRphgEtM4",
        "outputId": "fb2651d2-9840-4822-eeb8-0425f0538fdd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-------+-----+---+----+--------------+\n",
            "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+\n",
            "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|\n",
            "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|\n",
            "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets explore and clean data using Python API functions"
      ],
      "metadata": {
        "id": "hF-3Ik66xhCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType,FloatType\n",
        "data_df = data.withColumn(\"Avgtempcent\", data[\"AvgTemperature\"].cast(FloatType()))\n",
        "data_clean=data_df.where(\"Avgtempcent> -99\")"
      ],
      "metadata": {
        "id": "MwJ9ANT2C74J"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRgszh1dEHv9",
        "outputId": "b56904c3-2a40-49ed-b270-263d44d19b41"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+\n",
            "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|Avgtempcent|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+\n",
            "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|       64.2|\n",
            "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|       49.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|       48.8|\n",
            "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|       46.4|\n",
            "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|       47.9|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Transformations"
      ],
      "metadata": {
        "id": "FhuqwTZDF2qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# But Temperature given in Farenheight, Lets convert to Celcius scale"
      ],
      "metadata": {
        "id": "-e_yh_yIFdT3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df1 = data_clean.withColumn(\"Avgtempcentconv\", 5/9*(data_df[\"Avgtempcent\"]-9))\n",
        "data_df1.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHxuSiCziTz8",
        "outputId": "fc120ccf-5f63-4496-d5e0-e4289d4a9d32"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+------------------+\n",
            "|Region|Country|State|   City|Month|Day|Year|AvgTemperature|Avgtempcent|   Avgtempcentconv|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+------------------+\n",
            "|Africa|Algeria| null|Algiers|    1|  1|1995|          64.2|       64.2|30.666664971245662|\n",
            "|Africa|Algeria| null|Algiers|    1|  2|1995|          49.4|       49.4| 22.44444529215495|\n",
            "|Africa|Algeria| null|Algiers|    1|  3|1995|          48.8|       48.8| 22.11111068725586|\n",
            "|Africa|Algeria| null|Algiers|    1|  4|1995|          46.4|       46.4| 20.77777862548828|\n",
            "|Africa|Algeria| null|Algiers|    1|  5|1995|          47.9|       47.9|21.611111958821617|\n",
            "+------+-------+-----+-------+-----+---+----+--------------+-----------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Exploration"
      ],
      "metadata": {
        "id": "aofJd3_rGXIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean temp of all countries of Asia region for each year\n",
        "data_df1.select('Region','Country','City','Year','Avgtempcentconv').where(\"Region=='Asia'\")\\\n",
        ".groupBy(\"Country\",\"Year\").agg(F.mean('Avgtempcentconv')).orderBy(\"Country\",\"Year\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG7NcAqS3wSu",
        "outputId": "fd9200b2-b185-41a5-997b-c0c7ff2f9ba8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+--------------------+\n",
            "|   Country|Year|avg(Avgtempcentconv)|\n",
            "+----------+----+--------------------+\n",
            "|Bangladesh|1995|   39.08342950301002|\n",
            "|Bangladesh|1996|  38.758802764665724|\n",
            "|Bangladesh|1997|   37.86378861750306|\n",
            "|Bangladesh|1998|  39.048365898381654|\n",
            "|Bangladesh|1999|  37.826599336232384|\n",
            "+----------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mean temp of all countries of Asia region for each year\n",
        "data_df1.select('Region','Country','City','Year','Avgtempcentconv').where(\"Region=='Asia'\")\\\n",
        ".groupBy(\"Country\",\"Year\").agg(F.mean('Avgtempcentconv')).orderBy(\"Country\",\"Year\").explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vceWOaC6HT12",
        "outputId": "6f8847f0-6b7e-4dfe-f4da-95da1b1395d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [Country#17 ASC NULLS FIRST, Year#22 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(Country#17 ASC NULLS FIRST, Year#22 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#142]\n",
            "      +- HashAggregate(keys=[Country#17, Year#22], functions=[avg(Avgtempcentconv#136)])\n",
            "         +- Exchange hashpartitioning(Country#17, Year#22, 200), ENSURE_REQUIREMENTS, [id=#139]\n",
            "            +- HashAggregate(keys=[Country#17, Year#22], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "               +- Project [Country#17, Year#22, (cast((cast(AvgTemperature#23 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "                  +- Filter (((isnotnull(AvgTemperature#23) AND isnotnull(Region#16)) AND (cast(AvgTemperature#23 as float) > -99.0)) AND (Region#16 = Asia))\n",
            "                     +- FileScan csv [Region#16,Country#17,Year#22,AvgTemperature#23] Batched: false, DataFilters: [isnotnull(AvgTemperature#23), isnotnull(Region#16), (cast(AvgTemperature#23 as float) > -99.0), ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature), IsNotNull(Region), EqualTo(Region,Asia)], ReadSchema: struct<Region:string,Country:string,Year:string,AvgTemperature:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using SQL in Spark Jobs"
      ],
      "metadata": {
        "id": "2EXssmfKxV7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets create& register a view on our dataframe\n",
        "data_df1.createOrReplaceTempView(\"Temperature\")"
      ],
      "metadata": {
        "id": "NQgxatoGGe_7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets Run sql Query to fetch average temperature of countries for each year of Asia Region\n",
        "df=spark.sql(\"select Country,Year, AVG(Avgtempcentconv) from Temperature where region='Asia' group by 1,2 order by 1,2\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cR4zbuS5On-",
        "outputId": "d8a903cc-204a-41c5-a9f8-9dd5ceeeca59"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+--------------------+\n",
            "|   Country|Year|avg(Avgtempcentconv)|\n",
            "+----------+----+--------------------+\n",
            "|Bangladesh|1995|   39.08342950301002|\n",
            "|Bangladesh|1996|  38.758802764665724|\n",
            "|Bangladesh|1997|   37.86378861750306|\n",
            "|Bangladesh|1998|  39.048365898381654|\n",
            "|Bangladesh|1999|  37.826599336232384|\n",
            "+----------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, does we have same explain plan as before??"
      ],
      "metadata": {
        "id": "wLEyyDdPHxnJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx_wPhI9HsQO",
        "outputId": "bf257332-c86f-4c8b-d9be-ecad00525d84"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [Country#17 ASC NULLS FIRST, Year#22 ASC NULLS FIRST], true, 0\n",
            "   +- Exchange rangepartitioning(Country#17 ASC NULLS FIRST, Year#22 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#228]\n",
            "      +- HashAggregate(keys=[Country#17, Year#22], functions=[avg(Avgtempcentconv#136)])\n",
            "         +- Exchange hashpartitioning(Country#17, Year#22, 200), ENSURE_REQUIREMENTS, [id=#225]\n",
            "            +- HashAggregate(keys=[Country#17, Year#22], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "               +- Project [Country#17, Year#22, (cast((cast(AvgTemperature#23 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "                  +- Filter (((isnotnull(AvgTemperature#23) AND isnotnull(region#16)) AND (cast(AvgTemperature#23 as float) > -99.0)) AND (region#16 = Asia))\n",
            "                     +- FileScan csv [Region#16,Country#17,Year#22,AvgTemperature#23] Batched: false, DataFilters: [isnotnull(AvgTemperature#23), isnotnull(Region#16), (cast(AvgTemperature#23 as float) > -99.0), ..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature), IsNotNull(Region), EqualTo(Region,Asia)], ReadSchema: struct<Region:string,Country:string,Year:string,AvgTemperature:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average temperature of all countries\n",
        "df=spark.sql(\"select  AVG(Avgtempcentconv) from Temperature \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3geXbWnhtC0C",
        "outputId": "e25b66ed-1590-4ef4-8e99-13b590622b8f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|avg(Avgtempcentconv)|\n",
            "+--------------------+\n",
            "|  28.541046728168215|\n",
            "+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Does Spark allows Complex SQL queries e.g. CTEs , Subqueries ?\n"
      ],
      "metadata": {
        "id": "gO5johVnHCEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get all Asian countries, year and corresponding Average temp  having their Avg temp higher than avg global temperature till now \n",
        "spark.sql(\"\"\" \\\n",
        "WITH T_avg AS ( \\\n",
        "    select avg(Avgtempcentconv) as av from Temperature \\\n",
        "), \\\n",
        "CY_AVG AS (select Country,Year, AVG(Avgtempcentconv) as atc from Temperature where region='Asia' group by 1,2) \\\n",
        "select * from CY_AVG WHERE atc >= (SELECT av from T_avg) order by atc desc\"\"\" ).explain()"
      ],
      "metadata": {
        "id": "LJw8yvzJtCxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d84a1e-790b-4c2b-832c-1878bc32354b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Sort [atc#304 DESC NULLS LAST], true, 0\n",
            "   +- Exchange rangepartitioning(atc#304 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#318]\n",
            "      +- Filter (isnotnull(atc#304) AND (atc#304 >= Subquery subquery#302, [id=#310]))\n",
            "         :  +- Subquery subquery#302, [id=#310]\n",
            "         :     +- AdaptiveSparkPlan isFinalPlan=false\n",
            "         :        +- HashAggregate(keys=[], functions=[avg(Avgtempcentconv#136)])\n",
            "         :           +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [id=#308]\n",
            "         :              +- HashAggregate(keys=[], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "         :                 +- Project [(cast((cast(AvgTemperature#23 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "         :                    +- Filter (isnotnull(AvgTemperature#23) AND (cast(AvgTemperature#23 as float) > -99.0))\n",
            "         :                       +- FileScan csv [AvgTemperature#23] Batched: false, DataFilters: [isnotnull(AvgTemperature#23), (cast(AvgTemperature#23 as float) > -99.0)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature)], ReadSchema: struct<AvgTemperature:string>\n",
            "         +- HashAggregate(keys=[Country#306, Year#311], functions=[avg(Avgtempcentconv#136)])\n",
            "            +- Exchange hashpartitioning(Country#306, Year#311, 200), ENSURE_REQUIREMENTS, [id=#314]\n",
            "               +- HashAggregate(keys=[Country#306, Year#311], functions=[partial_avg(Avgtempcentconv#136)])\n",
            "                  +- Project [Country#306, Year#311, (cast((cast(AvgTemperature#312 as float) - 9.0) as double) * 0.5555555555555556) AS Avgtempcentconv#136]\n",
            "                     +- Filter (((isnotnull(AvgTemperature#312) AND isnotnull(region#305)) AND (cast(AvgTemperature#312 as float) > -99.0)) AND (region#305 = Asia))\n",
            "                        +- FileScan csv [Region#305,Country#306,Year#311,AvgTemperature#312] Batched: false, DataFilters: [isnotnull(AvgTemperature#312), isnotnull(Region#305), (cast(AvgTemperature#312 as float) > -99.0..., Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/content/city_temperature.csv], PartitionFilters: [], PushedFilters: [IsNotNull(AvgTemperature), IsNotNull(Region), EqualTo(Region,Asia)], ReadSchema: struct<Region:string,Country:string,Year:string,AvgTemperature:string>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets check the data of above query"
      ],
      "metadata": {
        "id": "PVUed27zXyVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\" \\\n",
        "WITH T_avg AS ( \\\n",
        "    select avg(Avgtempcentconv) as av from Temperature \\\n",
        "), \\\n",
        "CY_AVG AS (select Country,Year, AVG(Avgtempcentconv) as atc from Temperature where region='Asia' group by 1,2) \\\n",
        "select * from CY_AVG WHERE atc >= (SELECT av from T_avg) order by atc desc\"\"\" ).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4vQNFXjrmiB",
        "outputId": "984e70fa-ecff-4f3f-fc2e-c677a47f2d9f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------------------+\n",
            "|  Country|Year|               atc|\n",
            "+---------+----+------------------+\n",
            "| Thailand|1997| 42.77184178368322|\n",
            "|Indonesia|2002| 42.48148186496957|\n",
            "| Thailand|2006| 42.29984775816104|\n",
            "| Thailand|2005| 42.25281578075578|\n",
            "|Indonesia|2004|42.102481097208006|\n",
            "+---------+----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Average temperature of all countries\n",
        "df=spark.sql(\"DESCRIBE Temperature \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1Xtzk2SX2b7",
        "outputId": "3fb9db32-4d81-4af8-e168-94202569cc87"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+---------+-------+\n",
            "|       col_name|data_type|comment|\n",
            "+---------------+---------+-------+\n",
            "|         Region|   string|   null|\n",
            "|        Country|   string|   null|\n",
            "|          State|   string|   null|\n",
            "|           City|   string|   null|\n",
            "|          Month|   string|   null|\n",
            "|            Day|   string|   null|\n",
            "|           Year|   string|   null|\n",
            "| AvgTemperature|   string|   null|\n",
            "|    Avgtempcent|    float|   null|\n",
            "|Avgtempcentconv|   double|   null|\n",
            "+---------------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets explore Spark UI .To Enable UI in Google Collab, you need to set up ngrok auth which will provide a publlic URL for you SPARK UI . To set up your token, go to https://dashboard.ngrok.com/get-started/your-authtoken"
      ],
      "metadata": {
        "id": "iKDplO3Kxql-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#findspark will allow to locate spark installation in your enviornment\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "C_qDe86akaSN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import and initialize findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "iWIakdwlmGbK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get your spark installation directory\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VDg8awrNJZ_P",
        "outputId": "1ddea7e8-86dd-47bb-e5c1-c167c04ee7ba"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.8/dist-packages/pyspark'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download and install Ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#Unzip installer\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "#Setup your authtoken, here I have shared mine for reference \n",
        "!./ngrok authtoken 2LPTicfj3nE3ONtLFtvO2sy4Lch_2ZF1JA8KmVjLuMFLDuqid\n",
        "#generate public URL\n",
        "get_ipython().system_raw('./ngrok http 4050 &')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCc1n1uQuIaO",
        "outputId": "7f1202ea-c19b-43f5-8451-5c5bfd66ab84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-07 13:01:36--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 18.205.222.128, 54.237.133.81, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|18.205.222.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  8.57MB/s    in 1.5s    \n",
            "\n",
            "2023-02-07 13:01:37 (8.57 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Locate public URL\n",
        "!curl -s http://localhost:4040/api/tunnels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzjiQ6aWvdrl",
        "outputId": "2f0c62cc-b7f5-4ced-997d-63d2e20f89ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"tunnels\":[],\"uri\":\"/api/tunnels\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hUqICzdbNe0O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}